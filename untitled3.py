# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tu5tzRs-GQ4R37ylKV757er2IOEhrDN2
"""

# CodeGrade Tag Init1

from google.colab import drive
drive.mount('/content/drive')

"""Import Libraries"""

import os
import numpy as np
import cv2
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

"""Define Constants"""

DATASET_PATH = '/content/drive/MyDrive/archive'
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 10

""" Load Dataset"""

def load_images_from_folder(folder):
    images = []
    labels = []
    for sub_folder in os.listdir(folder):
        label = sub_folder
        sub_folder_path = os.path.join(folder, sub_folder)
        for filename in os.listdir(sub_folder_path):
            img_path = os.path.join(sub_folder_path, filename)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
            images.append(img)
            labels.append(label)
    return np.array(images), np.array(labels)

train_images, train_labels = load_images_from_folder(os.path.join(DATASET_PATH, 'Training'))
test_images, test_labels = load_images_from_folder(os.path.join(DATASET_PATH, 'Testing'))

# Correct label mismatch
label_map = {'glioma': 0, 'meningioma': 1, 'pituitary': 2, 'no_tumor': 3}
train_labels = np.array([label_map[label.replace('notumor', 'no_tumor')] for label in train_labels])
test_labels = np.array([label_map[label.replace('notumor', 'no_tumor')] for label in test_labels])

# One-hot encode labels
train_labels = to_categorical(train_labels, num_classes=4)
test_labels = to_categorical(test_labels, num_classes=4)

# Normalize images
train_images = train_images / 255.0
test_images = test_images / 255.0

def create_basic_cnn():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(4, activation='softmax')
    ])
    return model

def create_vgg16():
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
    base_model.trainable = False
    model = Sequential([
        base_model,
        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(4, activation='softmax')
    ])
    return model

def create_resnet50():
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
    base_model.trainable = False
    model = Sequential([
        base_model,
        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(4, activation='softmax')
    ])
    return model

from tensorflow.keras.optimizers import RMSprop

def compile_and_train(model, train_images, train_labels, val_images, val_labels):
    model.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
    history = model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[
        EarlyStopping(patience=5, restore_best_weights=True),
        ModelCheckpoint(f'{model.name}.h5', save_best_only=True)
    ])
    return history

train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)

basic_cnn = create_basic_cnn()
basic_cnn_history = compile_and_train(basic_cnn, train_images, train_labels, val_images, val_labels)

vgg16 = create_vgg16()
vgg16_history = compile_and_train(vgg16, train_images, train_labels, val_images, val_labels)

resnet50 = create_resnet50()
resnet50_history = compile_and_train(resnet50, train_images, train_labels, val_images, val_labels)

def evaluate_model(model, test_images, test_labels):
    results = model.evaluate(test_images, test_labels)
    print(f"Test Loss: {results[0]}, Test Accuracy: {results[1]}")

def plot_history(histories, titles):
    plt.figure(figsize=(20, 10))
    for i, history in enumerate(histories):
        plt.subplot(2, len(histories) // 2, i + 1)
        plt.plot(history.history['accuracy'], label='train_accuracy')
        plt.plot(history.history['val_accuracy'], label='val_accuracy')
        plt.title(titles[i])
        plt.xlabel('Epochs')
        plt.ylabel('Accuracy')
        plt.legend()
    plt.show()

# Plot the training history
histories = [resnet_history, vgg16_history, inception_history, vgg16_scratch_history]
titles = ['ResNet50', 'VGG16', 'InceptionV3', 'VGG16 (Scratch)']
plot_history(histories, titles)

# Evaluate models
print("ResNet50 Performance:")
evaluate_model(resnet_model, test_images, test_labels)

print("VGG16 Performance:")
evaluate_model(vgg16_model, test_images, test_labels)

print("InceptionV3 Performance:")
evaluate_model(inception_model, test_images, test_labels)

print("VGG16 (Scratch) Performance:")
evaluate_model(vgg16_scratch_model, test_images, test_labels)
