{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlvGpgHGUe0B",
        "outputId": "d4e1e4cf-654c-4f35-c01a-7b992606bf3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# CodeGrade Tag Init1\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwS6D4n6UrIP"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cl5djqYwUfej"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px_5ZBtzU6Nx"
      },
      "source": [
        "Define Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B7DML-nEUv7Z"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/archive'\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFvDgbQIVBFi"
      },
      "source": [
        " Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fN6gb2cHVADy"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for sub_folder in os.listdir(folder):\n",
        "        label = sub_folder\n",
        "        sub_folder_path = os.path.join(folder, sub_folder)\n",
        "        for filename in os.listdir(sub_folder_path):\n",
        "            img_path = os.path.join(sub_folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "train_images, train_labels = load_images_from_folder(os.path.join(DATASET_PATH, 'Training'))\n",
        "test_images, test_labels = load_images_from_folder(os.path.join(DATASET_PATH, 'Testing'))\n",
        "\n",
        "# Correct label mismatch\n",
        "label_map = {'glioma': 0, 'meningioma': 1, 'pituitary': 2, 'no_tumor': 3}\n",
        "train_labels = np.array([label_map[label.replace('notumor', 'no_tumor')] for label in train_labels])\n",
        "test_labels = np.array([label_map[label.replace('notumor', 'no_tumor')] for label in test_labels])\n",
        "\n",
        "# One-hot encode labels\n",
        "train_labels = to_categorical(train_labels, num_classes=4)\n",
        "test_labels = to_categorical(test_labels, num_classes=4)\n",
        "\n",
        "# Normalize images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CD1gvEz6U5Kj"
      },
      "outputs": [],
      "source": [
        "def create_basic_cnn():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "H7NjUwxnV57V"
      },
      "outputs": [],
      "source": [
        "def create_vgg16():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    base_model.trainable = False\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "of8DK0JLV_dZ"
      },
      "outputs": [],
      "source": [
        "def create_resnet50():\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    base_model.trainable = False\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WWJoMvs6WI8Z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "def compile_and_train(model, train_images, train_labels, val_images, val_labels):\n",
        "    model.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[\n",
        "        EarlyStopping(patience=5, restore_best_weights=True),\n",
        "        ModelCheckpoint(f'{model.name}.h5', save_best_only=True)\n",
        "    ])\n",
        "    return history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CiB9LN9WNDr"
      },
      "outputs": [],
      "source": [
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGYr56LaWemc",
        "outputId": "715e7a10-413a-459b-f159-24d55cb56da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "124/124 [==============================] - 127s 1s/step - loss: 0.8571 - accuracy: 0.6359 - val_loss: 0.6700 - val_accuracy: 0.7061\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 129s 1s/step - loss: 0.5363 - accuracy: 0.7848 - val_loss: 0.4477 - val_accuracy: 0.8404\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 125s 1s/step - loss: 0.4042 - accuracy: 0.8477 - val_loss: 0.2919 - val_accuracy: 0.8909\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 125s 1s/step - loss: 0.3226 - accuracy: 0.8712 - val_loss: 0.2476 - val_accuracy: 0.9182\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 123s 989ms/step - loss: 0.2517 - accuracy: 0.9025 - val_loss: 0.2420 - val_accuracy: 0.9051\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 128s 1s/step - loss: 0.1946 - accuracy: 0.9260 - val_loss: 0.2229 - val_accuracy: 0.9253\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 127s 1s/step - loss: 0.1740 - accuracy: 0.9321 - val_loss: 0.2690 - val_accuracy: 0.8818\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 129s 1s/step - loss: 0.1396 - accuracy: 0.9505 - val_loss: 0.2476 - val_accuracy: 0.9222\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 125s 1s/step - loss: 0.1030 - accuracy: 0.9641 - val_loss: 0.2486 - val_accuracy: 0.9374\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 124s 1s/step - loss: 0.0817 - accuracy: 0.9722 - val_loss: 0.1736 - val_accuracy: 0.9545\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 914s 7s/step - loss: 0.8100 - accuracy: 0.7187 - val_loss: 0.5995 - val_accuracy: 0.7283\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 910s 7s/step - loss: 0.4436 - accuracy: 0.8313 - val_loss: 0.3197 - val_accuracy: 0.8879\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 914s 7s/step - loss: 0.3828 - accuracy: 0.8490 - val_loss: 0.3162 - val_accuracy: 0.8838\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 910s 7s/step - loss: 0.3410 - accuracy: 0.8644 - val_loss: 0.2653 - val_accuracy: 0.9101\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 905s 7s/step - loss: 0.3168 - accuracy: 0.8806 - val_loss: 0.2351 - val_accuracy: 0.9121\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 913s 7s/step - loss: 0.2954 - accuracy: 0.8859 - val_loss: 0.2340 - val_accuracy: 0.9192\n",
            "Epoch 7/10\n",
            " 77/124 [=================>............] - ETA: 4:29 - loss: 0.2662 - accuracy: 0.8941"
          ]
        }
      ],
      "source": [
        "basic_cnn = create_basic_cnn()\n",
        "basic_cnn_history = compile_and_train(basic_cnn, train_images, train_labels, val_images, val_labels)\n",
        "\n",
        "vgg16 = create_vgg16()\n",
        "vgg16_history = compile_and_train(vgg16, train_images, train_labels, val_images, val_labels)\n",
        "\n",
        "resnet50 = create_resnet50()\n",
        "resnet50_history = compile_and_train(resnet50, train_images, train_labels, val_images, val_labels)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}