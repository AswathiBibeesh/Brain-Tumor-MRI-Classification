# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jtt9Zo8lEPmmbwnNOaypVx8QslhMhWwC
"""

# CodeGrade Tag Init1

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, InceptionV3, VGG16
from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, BatchNormalization, Flatten, Conv2D, MaxPool2D
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import get_custom_objects

glioma="dataset/Training/glioma"
image_fol= os.listdir(glioma)

plt.figure(figsize=(10, 10))

for i in range(25):
    image_p = os.path.join(glioma, image_fol[i])
    image = cv2.imread(image_p)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.subplot(5, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')

plt.suptitle('Sample Glioma Images', fontsize=16)
plt.tight_layout()
plt.show()

meningioma_dir="dataset/Training/meningioma/"
image_fol= os.listdir(meningioma_dir)

plt.figure(figsize=(10, 10))

for i in range(25):
    image_p = os.path.join(meningioma_dir, image_fol[i])
    image = cv2.imread(image_p)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.subplot(5, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')

plt.suptitle('Sample Meningioma Images', fontsize=16)
plt.tight_layout()
plt.show()

notumor_dir="dataset/Training/notumor/"
image_fol= os.listdir(notumor_dir)

plt.figure(figsize=(10, 10))

for i in range(25):
    image_p = os.path.join(notumor_dir, image_fol[i])
    image = cv2.imread(image_p)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.subplot(5, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')

plt.suptitle('Sample Images without Tumor', fontsize=16)
plt.tight_layout()
plt.show()

pituitary_dir="dataset/Training/pituitary/"
image_fol= os.listdir(pituitary_dir)

plt.figure(figsize=(10, 10))

for i in range(25):
    image_p = os.path.join(pituitary_dir, image_fol[i])
    image = cv2.imread(image_p)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.subplot(5, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')

plt.suptitle('Sample Pituitary Tumor Images', fontsize=16)
plt.tight_layout()
plt.show()

training_data="dataset/Training"
testing_data="dataset/Testing/"
validation_data="dataset/Testing/"

filepath=[]
label=[]
image_folder=os.listdir(training_data)
for folder in image_folder:
    folder_path=os.path.join(training_data,folder)
    filelist=os.listdir(folder_path)
    for file in filelist:
        new_path=os.path.join(folder_path,file)
        filepath.append(new_path)
        label.append(folder)


image_data=pd.Series(filepath,name="image_data")
label_data=pd.Series(label,name="label")
train_dataset=pd.concat([image_data,label_data],axis=1)
train_dataset.head()

train_dataset.shape

train_dataset.isnull().sum()

train_dataset["label"].value_counts()

filepath=[]
label=[]
image_folder=os.listdir(testing_data)
for folder in image_folder:
    folder_path=os.path.join(testing_data,folder)
    filelist=os.listdir(folder_path)
    for file in filelist:
        new_path=os.path.join(folder_path,file)
        filepath.append(new_path)
        label.append(folder)


image_data=pd.Series(filepath,name="image_data")
label_data=pd.Series(label,name="label")
test_dataset=pd.concat([image_data,label_data],axis=1)
test_dataset.head()

test_dataset.shape

test_dataset.isnull().sum()

test_dataset["label"].value_counts()

filepath=[]
label=[]
image_folder=os.listdir(validation_data)
for folder in image_folder:
    folder_path=os.path.join(validation_data,folder)
    filelist=os.listdir(folder_path)
    for file in filelist:
        new_path=os.path.join(folder_path,file)
        filepath.append(new_path)
        label.append(folder)


image_data=pd.Series(filepath,name="image_data")
label_data=pd.Series(label,name="label")
valid_dataset=pd.concat([image_data,label_data],axis=1)
valid_dataset.head()

valid_dataset.shape

valid_dataset["label"].value_counts()

batch_size=16
color_channel=3
image_shape=(224,224,3)
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_generator = ImageDataGenerator(
    rescale=1./255,)

test_generator=ImageDataGenerator(rescale=1./255)

train_data_generator=train_generator.flow_from_dataframe(train_dataset,x_col="image_data",y_col="label",
                                                        target_size=image_shape[:2],
                                                        color_mode="rgb",
                                                        shuffle=True,
                                                        batch_size=batch_size)

test_data_generator=test_generator.flow_from_dataframe(test_dataset,x_col="image_data",y_col="label",
                                                        target_size=image_shape[:2],
                                                        color_mode="rgb",
                                                        shuffle=False,
                                                        batch_size=batch_size)

valid_data_generator=test_generator.flow_from_dataframe(valid_dataset,x_col="image_data",y_col="label",
                                                        target_size=image_shape[:2],
                                                        color_mode="rgb",
                                                        shuffle=True,
                                                        batch_size=batch_size)

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)


for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(1024, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
predictions = Dense(len(train_dataset["label"].unique()), activation='softmax')(x)


model = Model(inputs=base_model.input, outputs=predictions)


model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint('ResNet_model.h5', monitor='val_loss', save_best_only=True, mode='min')
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)


history = model.fit(
    train_data_generator,
    epochs=100,
    validation_data=valid_data_generator,
    callbacks=[checkpoint, early_stopping]
)


test_loss, test_accuracy = model.evaluate(test_data_generator)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')

base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=image_shape)


for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(len(train_dataset["label"].unique()), activation='softmax')(x)


model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint('inceptionv3_model.h5', monitor='val_loss', save_best_only=True, mode='min')


history = model.fit(
    train_data_generator,
    epochs=100,
    validation_data=valid_data_generator,
    callbacks=[checkpoint]
)


test_loss, test_accuracy = model.evaluate(test_data_generator)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')

model = Sequential()

model.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=image_shape))
model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Flatten())
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(len(train_dataset["label"].unique()), activation='softmax'))

model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint('VGG16_modelnewf.h5', monitor='val_loss', save_best_only=True, mode='min')
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)

history = model.fit(
    train_data_generator,
    epochs=30,
    validation_data=valid_data_generator,
    callbacks=[checkpoint, early_stopping, reduce_lr]
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_data_generator)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(len(train_dataset["label"].unique()), activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint('/content/drive/MyDrive/aswathybrain/vgg16.keras',
                              monitor='val_loss',
                              save_best_only=True,
                              mode='min',
                              verbose=1)

history = model.fit(
    train_data_generator,
    epochs=30,
    validation_data=valid_data_generator,
    callbacks=[checkpoint]
)

model.save('/content/drive/MyDrive/aswathybrain/vgg16pre.h5')

model_path = 'VGG16_model.h5'
model = load_model(model_path,compile=False)

def preprocess_image(image_p, target_size=(224, 224)):
    image = load_img(image_p, target_size=target_size)
    img_array = img_to_array(image)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0
    return img_array

def predict_image(image_p):
    img_array = preprocess_image(image_p)
    predictions = model.predict(img_array)
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    class_labels = list(train_data_generator.class_indices.keys())
    predicted_class_label = class_labels[predicted_class_index]
    return predicted_class_label


image_p = 'dataset\Testing\meningioma\Te-me_0020.jpg'
predicted_label = predict_image(image_p)
print(f'The predicted label for the image is: {predicted_label}')

from tensorflow.keras.models import load_model

resnet_model_path = 'ResNet_model.h5'
inception_model_path = 'inceptionv3_model.h5'
vgg16_model_path = 'VGG16_model.h5'

resnet_model = load_model(resnet_model_path,compile=False)
inception_model = load_model(inception_model_path,compile=False)
vgg16_model = load_model(vgg16_model_path,compile=False)

def predict_images(model, dataset, class_labels):
    y_true = []
    y_pred = []
    for idx, row in dataset.iterrows():
        image_p = row['image_data']
        true_label = row['label']
        image = load_and_preprocess_image(image_p)
        predictions = model.predict(image)
        predicted_class = np.argmax(predictions)
        predicted_label = class_labels[predicted_class]
        y_true.append(true_label)
        y_pred.append(predicted_label)
    return y_true, y_pred

class_labels = train_dataset["label"].unique()

def load_and_preprocess_image(image_p, target_size=(224, 224)):
   image = cv2.imread(image_p)
   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
   image = cv2.resize(image, target_size)
   image = img_to_array(image) / 255.0
   image = np.expand_dims(image, axis=0)
   return image

y_true_resnet, y_pred_resnet = predict_images(resnet_model, test_dataset, class_labels)
y_true_inception, y_pred_inception = predict_images(inception_model, test_dataset, class_labels)
y_true_vgg16, y_pred_vgg16 = predict_images(vgg16_model, test_dataset, class_labels)

conf_matrix_resnet = confusion_matrix(y_true_resnet, y_pred_resnet, labels=class_labels)
conf_matrix_inception = confusion_matrix(y_true_inception, y_pred_inception, labels=class_labels)
conf_matrix_vgg16 = confusion_matrix(y_true_vgg16, y_pred_vgg16, labels=class_labels)

print("ResNet Classification Report:")
print(classification_report(y_true_resnet, y_pred_resnet, target_names=class_labels))

print("InceptionV3 Classification Report:")
print(classification_report(y_true_inception, y_pred_inception, target_names=class_labels))

print("VGG16 Classification Report:")
print(classification_report(y_true_vgg16, y_pred_vgg16, target_names=class_labels))

def plot_confusion_matrix(conf_matrix, class_labels, title):
    plt.figure(figsize=(10, 8))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(title)
    plt.show()

plot_confusion_matrix(conf_matrix_resnet, class_labels, 'ResNet Confusion Matrix')
plot_confusion_matrix(conf_matrix_inception, class_labels, 'InceptionV3 Confusion Matrix')
plot_confusion_matrix(conf_matrix_vgg16, class_labels, 'VGG16 Confusion Matrix')

import matplotlib.pyplot as plt
import numpy as np

models = ['ResNet', 'InceptionV3', 'VGG16']
accuracy = [0.91, 0.96, 0.96]
precision = [0.91, 0.96, 0.96]
recall = [0.91, 0.96, 0.96]
f1_score = [0.91, 0.96, 0.96]

bar_width = 0.2

r1 = np.arange(len(models))
r2 = [x + bar_width for x in r1]
r3 = [x + bar_width for x in r2]
r4 = [x + bar_width for x in r3]

plt.figure(figsize=(10, 6))

plt.bar(r1, accuracy, color='b', width=bar_width, edgecolor='grey', label='Accuracy')
plt.bar(r2, precision, color='g', width=bar_width, edgecolor='grey', label='Precision')
plt.bar(r3, recall, color='r', width=bar_width, edgecolor='grey', label='Recall')
plt.bar(r4, f1_score, color='y', width=bar_width, edgecolor='grey', label='F1-Score')

plt.xlabel('Models', fontweight='bold')
plt.ylabel('Scores', fontweight='bold')
plt.xticks([r + bar_width for r in range(len(models))], models)
plt.title('Comparison of ResNet, InceptionV3, and VGG16 Performance Metrics')
plt.legend()

plt.show()

path='vgg16pre.h5'
pre=load_model(path,compile=False)
y_true_vgg16pre, y_pred_vgg16pre = predict_images(pre, test_dataset, class_labels)

print("VGG16 pre-trained model Classification Report:")
print(classification_report(y_true_vgg16pre, y_pred_vgg16pre, target_names=class_labels))

conf_matrix_vgg16pre = confusion_matrix(y_true_vgg16pre, y_pred_vgg16pre, labels=class_labels)

def plot_confusion_matrix(conf_matrix, class_labels, title):
    plt.figure(figsize=(10, 8))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(title)
    plt.show()
plot_confusion_matrix(conf_matrix_vgg16pre, class_labels, 'VGG16 pre-trained model Confusion Matrix')

models = ['VGG16 pre-trained', 'VGG16']
accuracy = [ 0.86, 0.96]
precision = [ 0.86, 0.96]
recall = [ 0.84, 0.96]
f1_score = [ 0.84, 0.96]

bar_width = 0.2

r1 = np.arange(len(models))
r2 = [x + bar_width for x in r1]
r3 = [x + bar_width for x in r2]
r4 = [x + bar_width for x in r3]

plt.figure(figsize=(10, 6))

plt.bar(r1, accuracy, color='b', width=bar_width, edgecolor='grey', label='Accuracy')
plt.bar(r2, precision, color='g', width=bar_width, edgecolor='grey', label='Precision')
plt.bar(r3, recall, color='r', width=bar_width, edgecolor='grey', label='Recall')
plt.bar(r4, f1_score, color='y', width=bar_width, edgecolor='grey', label='F1-Score')


plt.xlabel('Models', fontweight='bold')
plt.ylabel('Scores', fontweight='bold')
plt.xticks([r + bar_width for r in range(len(models))], models)
plt.title('Comparison of VGG16 pre-trained and VGG16 models Performance Metrics')
plt.legend()

plt.show()

model_path = 'VGG16_model.h5'
model = load_model(model_path,compile=False)

def load_and_preprocess_image(image_p, target_size=(224, 224)):
   image = cv2.imread(image_p)
   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
   image = cv2.resize(image, target_size)
   image = img_to_array(image) / 255.0
   image = np.expand_dims(image, axis=0)
    returnimage

def predict_image(model, image_p, class_labels):
   image = load_and_preprocess_image(image_p)
    predictions = model.predict(image)
    predicted_class = np.argmax(predictions)
    predicted_label = class_labels[predicted_class]
    return predicted_label, predictions


class_labels = ["glioma","meningioma","notumor","pituitary"]

image_p = 'dataset/Testing/notumor/Te-no_0019.jpg'

predicted_label, predictions = predict_image(model, image_p, class_labels)

image = cv2.imread(image_p)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

plt.imshow(image)
plt.title(f'Predicted: {predicted_label}')
plt.axis('off')
plt.show()

print(f'Prediction probabilities: {predictions}')

