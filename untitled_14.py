# -*- coding: utf-8 -*-
"""untitled 14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RKufbt_F_kBei2sDtVoQQPhdtIAZFy5G
"""

import os
import cv2
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, InceptionV3, VGG16
from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, BatchNormalization, Flatten, Conv2D, MaxPool2D
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import get_custom_objects

#Define the path glioma
glioma="dataset/Training/glioma"
#list all images in the directory
image_fol= os.listdir(glioma)

#set up the plot
plt.figure(figsize=(10, 10))

#loop to display the first 25 images
for i in range(25):
    image_p = os.path.join(glioma, image_fol[i])
    image = cv2.imread(image_p)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.subplot(5, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')

#Add title and adjust layout
plt.suptitle('Sample Glioma Images', fontsize=16)
plt.tight_layout()
plt.show()

# Define the path meningioma
meningioma_dir="dataset/Training/meningioma/"
# list all images in the directory
image_fol= os.listdir(meningioma_dir)
# set up the plot
plt.figure(figsize=(10, 10))
# loop to display the first 25 images
for i in range(25):
    image_p = os.path.join(meningioma_dir, image_fol[i])
    image = cv2.imread(image_p)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.subplot(5, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')
# Add title and adjust layout
plt.suptitle('Sample Meningioma Images', fontsize=16)
plt.tight_layout()
plt.show()

# Define the path notumor
notumor_dir="dataset/Training/notumor/"
# List all images in the directory
image_fol= os.listdir(notumor_dir)
# set up the plot
plt.figure(figsize=(10, 10))
# loop to display the first 25 images
for i in range(25):
    image_p = os.path.join(notumor_dir, image_fol[i])
    image = cv2.imread(image_p)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.subplot(5, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')
# Add title and adjust layout
plt.suptitle('Sample Images without Tumor', fontsize=16)
plt.tight_layout()
plt.show()

# Define the path using a string variable
pituitary_dir="dataset/Training/pituitary/"
# List all image in the directory
image_fol= os.listdir(pituitary_dir)
# set up the plot
plt.figure(figsize=(10, 10))
# loop to display the first 25 images
for i in range(25):
    image_p = os.path.join(pituitary_dir, image_fol[i])
    image = cv2.imread(image_p)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.subplot(5, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')
# Add title and adjust layout
plt.suptitle('Sample Pituitary Tumor Images', fontsize=16)
plt.tight_layout()
plt.show()

# Defines the path for the training dataset.
training_data="dataset/Training"
#Defines the path for the testing dataset.
testing_data="dataset/Testing/"
#Defines the path for the validation dataset (have the same path as testing here)
validation_data="dataset/Testing/"

# Initialize lists
filepath=[]
label=[]
# List all folders in the training directory
image_folder=os.listdir(training_data)
# Loop through each folder (representing a class)
for folder in image_folder:
    folder_path=os.path.join(training_data,folder)
    filelist=os.listdir(folder_path)
     # Loop through each file in the folder
    for file in filelist:
        new_path=os.path.join(folder_path,file)
        filepath.append(new_path)
        label.append(folder)

# Create a Pandas DataFrame
image_data=pd.Series(filepath,name="image_data")
label_data=pd.Series(label,name="label")
train_dataset=pd.concat([image_data,label_data],axis=1)

# Display the first 5 rows of the dataset
train_dataset.head()

# Get the shape of the training dataset
train_dataset.shape

# Calculate the number of missing values
train_dataset.isnull().sum()

# Get the counts of each label
train_dataset["label"].value_counts()

# Initialize lists
filepath=[]
label=[]
# List all folders in the testing directory
image_folder=os.listdir(testing_data)
# Loop through each folder
for folder in image_folder:
    folder_path=os.path.join(testing_data,folder)
    filelist=os.listdir(folder_path)

    # Loop through each file in the folder
    for file in filelist:
        new_path=os.path.join(folder_path,file)
        filepath.append(new_path)
        label.append(folder)

# Create a Pandas DataFrame
image_data=pd.Series(filepath,name="image_data")
label_data=pd.Series(label,name="label")
test_dataset=pd.concat([image_data,label_data],axis=1)
# Display the first 5 rows of the dataset
test_dataset.head()

# Get the shape of the testing dataset
test_dataset.shape

# Calculate the number of missing values
test_dataset.isnull().sum()

# Get the counts of each label
test_dataset["label"].value_counts()

# Initialize lists
filepath=[]
label=[]
# List all folders in the validation directory
image_folder=os.listdir(validation_data)
# Loop through each folder
for folder in image_folder:
    folder_path=os.path.join(validation_data,folder)
    filelist=os.listdir(folder_path)
     # Loop through each file in the folder
    for file in filelist:
        new_path=os.path.join(folder_path,file)
        filepath.append(new_path)
        label.append(folder)

# Create a Pandas DataFrame
image_data=pd.Series(filepath,name="image_data")
label_data=pd.Series(label,name="label")
valid_dataset=pd.concat([image_data,label_data],axis=1)
# Display the first 5 rows of the dataset
valid_dataset.head()

# Get the shape of the validation dataset
valid_dataset.shape

# Calculate the number of missing values
valid_dataset["label"].value_counts()

from tensorflow.keras.preprocessing.image import ImageDataGenerator
# Define parameters
batch_size=16
color_channel=3
image_shape=(224,224,3)

# Create ImageDataGenerators
train_generator = ImageDataGenerator(
    rescale=1./255,)

test_generator=ImageDataGenerator(rescale=1./255)

# Set up data generators
train_data_generator=train_generator.flow_from_dataframe(train_dataset,x_col="image_data",y_col="label",
                                                        target_size=image_shape[:2],
                                                        color_mode="rgb",
                                                        shuffle=True,
                                                        batch_size=batch_size)

test_data_generator=test_generator.flow_from_dataframe(test_dataset,x_col="image_data",y_col="label",
                                                        target_size=image_shape[:2],
                                                        color_mode="rgb",
                                                        shuffle=False,
                                                        batch_size=batch_size)

valid_data_generator=test_generator.flow_from_dataframe(valid_dataset,x_col="image_data",y_col="label",
                                                        target_size=image_shape[:2],
                                                        color_mode="rgb",
                                                        shuffle=True,
                                                        batch_size=batch_size)

# Load the ResNet50 model
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add custom top layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(1024, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
predictions = Dense(len(train_dataset["label"].unique()), activation='softmax')(x)

# Create the model
model = Model(inputs=base_model.input, outputs=predictions)


# Compile the model
model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# Define callbacks
checkpoint = ModelCheckpoint('ResNet_model.h5', monitor='val_loss', save_best_only=True, mode='min')
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(
    train_data_generator,
    epochs=100,
    validation_data=valid_data_generator,
    callbacks=[checkpoint, early_stopping]
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_data_generator)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')

# Load the InceptionV3 model
base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=image_shape)

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add custom top layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(len(train_dataset["label"].unique()), activation='softmax')(x)

# Create the model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# Define the checkpoint callback
checkpoint = ModelCheckpoint('inceptionv3_model.h5', monitor='val_loss', save_best_only=True, mode='min')

# Train the model
history = model.fit(
    train_data_generator,
    epochs=100,
    validation_data=valid_data_generator,
    callbacks=[checkpoint]
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_data_generator)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')

# Define the model
model = Sequential()

# Add convolutional layers with batch normalization and max pooling
model.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=image_shape))
model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(MaxPool2D((2, 2), strides=(2, 2)))
model.add(BatchNormalization())

# Flatten the output and add dense layers
model.add(Flatten())
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(len(train_dataset["label"].unique()), activation='softmax'))

# Compile the model
model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])


# Define callbacks
checkpoint = ModelCheckpoint('VGG16_modelnewf.h5', monitor='val_loss', save_best_only=True, mode='min')
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)

# Train the model
history = model.fit(
    train_data_generator,
    epochs=30,
    validation_data=valid_data_generator,
    callbacks=[checkpoint, early_stopping, reduce_lr]
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_data_generator)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')

# Load the VGG16 base model with pre-trained ImageNet weights, excluding the top layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze all layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom top layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(len(train_dataset["label"].unique()), activation='softmax')(x)

# Create the complete model with base VGG16 model and custom top layers
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Define the checkpoint callback to save the best model based on validation loss
checkpoint = ModelCheckpoint('/content/drive/MyDrive/aswathybrain/vgg16.keras',
                              monitor='val_loss',
                              save_best_only=True,
                              mode='min',
                              verbose=1)

# Train the model
history = model.fit(
    train_data_generator,
    epochs=30,
    validation_data=valid_data_generator,
    callbacks=[checkpoint]
)

# Save the trained model
model.save('/content/drive/MyDrive/aswathybrain/vgg16pre.h5')

# Path to the saved model
model_path = 'VGG16_model.h5'
# Load the model without compiling it (compilation is not needed for inference)
model = load_model(model_path,compile=False)

def preprocess_image(image_p, target_size=(224, 224)):
     # Load the image with the target size
    image = load_img(image_p, target_size=target_size)
     # Convert the image to a numpy array
    img_array = img_to_array(image)
    # Add a batch dimension
    img_array = np.expand_dims(img_array, axis=0)
     # Normalize the image array
    img_array = img_array / 255.0
    return img_array

def predict_image(image_p):
    # Preprocess the image
    img_array = preprocess_image(image_p)
     # Perform prediction
    predictions = model.predict(img_array)
    # Get the predicted class index
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    # Retrieve the class labels
    class_labels = list(train_data_generator.class_indices.keys())
      # Get the predicted class label
    predicted_class_label = class_labels[predicted_class_index]
    return predicted_class_label

# Path to the image to be tested
image_p = 'dataset\Testing\meningioma\Te-me_0020.jpg'

# Predict the label of the image
predicted_label = predict_image(image_p)
# Print the predicted label
print(f'The predicted label for the image is: {predicted_label}')

from tensorflow.keras.models import load_model

# Paths to the saved models
resnet_model_path = 'ResNet_model.h5'
inception_model_path = 'inceptionv3_model.h5'
vgg16_model_path = 'VGG16_model.h5'

# Load the ResNet model without compiling it
resnet_model = load_model(resnet_model_path,compile=False)
# Load the InceptionV3 model without compiling it
inception_model = load_model(inception_model_path,compile=False)
# Load the VGG16 model without compiling it
vgg16_model = load_model(vgg16_model_path,compile=False)

def predict_images(model, dataset, class_labels):
    y_true = []
    y_pred = []
    # Iterate through each row in the dataset
    for idx, row in dataset.iterrows():
        # Get the path and true label from the dataset
        image_p = row['image_data']
        true_label = row['label']
        # Load and preprocess the image
        image = load_and_preprocess_image(image_p)
        # Make prediction
        predictions = model.predict(image)
        # Get the index of the highest probability
        predicted_class = np.argmax(predictions)
        # Map index to class label
        predicted_label = class_labels[predicted_class]
        # Append true and predicted labels to respective lists
        y_true.append(true_label)
        y_pred.append(predicted_label)
    return y_true, y_pred

# Define class labels based on unique values in the training dataset
class_labels = train_dataset["label"].unique()

def load_and_preprocess_image(image_p, target_size=(224, 224)):
   # Load the image from the file path using OpenCV
   image = cv2.imread(image_p)
   # Convert the image from BGR (OpenCV format) to RGB (model format)
   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
   # Resize the image to the target size
   image = cv2.resize(image, target_size)
   # Convert the image to a numpy array and normalize pixel values to [0, 1]
   image = img_to_array(image) / 255.0
   # Add a batch dimension (1, height, width, channels) for model input
   image = np.expand_dims(image, axis=0)
   return image

# Predict labels using the ResNet model
y_true_resnet, y_pred_resnet = predict_images(resnet_model, test_dataset, class_labels)
# Predict labels using the InceptionV3 model
y_true_inception, y_pred_inception = predict_images(inception_model, test_dataset, class_labels)
# Predict labels using the VGG16 model
y_true_vgg16, y_pred_vgg16 = predict_images(vgg16_model, test_dataset, class_labels)

# Compute the confusion matrix for the ResNet model
conf_matrix_resnet = confusion_matrix(y_true_resnet, y_pred_resnet, labels=class_labels)
# Compute the confusion matrix for the InceptionV3 model
conf_matrix_inception = confusion_matrix(y_true_inception, y_pred_inception, labels=class_labels)
# Compute the confusion matrix for the VGG16 model
conf_matrix_vgg16 = confusion_matrix(y_true_vgg16, y_pred_vgg16, labels=class_labels)

# Print the classification report for the ResNet model
print("ResNet Classification Report:")
print(classification_report(y_true_resnet, y_pred_resnet, target_names=class_labels))

# Print the classification report for the InceptionV3 model
print("InceptionV3 Classification Report:")
print(classification_report(y_true_inception, y_pred_inception, target_names=class_labels))

# Print the classification report for the Vgg16 model
print("VGG16 Classification Report:")
print(classification_report(y_true_vgg16, y_pred_vgg16, target_names=class_labels))

def plot_confusion_matrix(conf_matrix, class_labels, title):
    plt.figure(figsize=(10, 8))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(title)
    plt.show()

# Plot confusion matrices for each model with titles
plot_confusion_matrix(conf_matrix_resnet, class_labels, 'ResNet Confusion Matrix')
plot_confusion_matrix(conf_matrix_inception, class_labels, 'InceptionV3 Confusion Matrix')
plot_confusion_matrix(conf_matrix_vgg16, class_labels, 'VGG16 Confusion Matrix')

import matplotlib.pyplot as plt
import numpy as np

# Define the performance metrics for each model
models = ['ResNet', 'InceptionV3', 'VGG16']
accuracy = [0.91, 0.96, 0.96]
precision = [0.91, 0.96, 0.96]
recall = [0.91, 0.96, 0.96]
f1_score = [0.91, 0.96, 0.96]

# Set bar width and positions for grouped bars
bar_width = 0.2

r1 = np.arange(len(models))
r2 = [x + bar_width for x in r1]
r3 = [x + bar_width for x in r2]
r4 = [x + bar_width for x in r3]

# Create the bar plot
plt.figure(figsize=(10, 6))

# Plot bars for each metric
plt.bar(r1, accuracy, color='b', width=bar_width, edgecolor='grey', label='Accuracy')
plt.bar(r2, precision, color='g', width=bar_width, edgecolor='grey', label='Precision')
plt.bar(r3, recall, color='r', width=bar_width, edgecolor='grey', label='Recall')
plt.bar(r4, f1_score, color='y', width=bar_width, edgecolor='grey', label='F1-Score')

# Add labels and title
plt.xlabel('Models', fontweight='bold')
plt.ylabel('Scores', fontweight='bold')
plt.xticks([r + bar_width for r in range(len(models))], models)
plt.title('Comparison of ResNet, InceptionV3, and VGG16 Performance Metrics')
plt.legend()

# Display the plot
plt.show()

# Define the path to the pre-trained VGG16 model
path='vgg16pre.h5'
# Load the pre-trained VGG16 model
pre=load_model(path,compile=False)
# Predict labels for the test dataset using the pre-trained VGG16 model
y_true_vgg16pre, y_pred_vgg16pre = predict_images(pre, test_dataset, class_labels)

# Print classification report for the VGG16 pre-trained model
print("VGG16 pre-trained model Classification Report:")
print(classification_report(y_true_vgg16pre, y_pred_vgg16pre, target_names=class_labels))

# Compute the confusion matrix for the VGG16 pre-trained model
conf_matrix_vgg16pre = confusion_matrix(y_true_vgg16pre, y_pred_vgg16pre, labels=class_labels)

# Function to plot the confusion matrix
def plot_confusion_matrix(conf_matrix, class_labels, title):
    plt.figure(figsize=(10, 8))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(title)
    plt.show()
# Plot the confusion matrix for the VGG16 pre-trained model
plot_confusion_matrix(conf_matrix_vgg16pre, class_labels, 'VGG16 pre-trained model Confusion Matrix')

# Define the models and their corresponding performance metrics
models = ['VGG16 pre-trained', 'VGG16']
accuracy = [ 0.86, 0.96]
precision = [ 0.86, 0.96]
recall = [ 0.84, 0.96]
f1_score = [ 0.84, 0.96]

# Set the width of the bars in the bar plot
bar_width = 0.2

# Define the position of the bars on the x-axis
r1 = np.arange(len(models))
r2 = [x + bar_width for x in r1]
r3 = [x + bar_width for x in r2]
r4 = [x + bar_width for x in r3]

# Create the bar plot
plt.figure(figsize=(10, 6))

# Plot Accuracy
plt.bar(r1, accuracy, color='b', width=bar_width, edgecolor='grey', label='Accuracy')
# Plot Precision
plt.bar(r2, precision, color='g', width=bar_width, edgecolor='grey', label='Precision')
# Plot Recall
plt.bar(r3, recall, color='r', width=bar_width, edgecolor='grey', label='Recall')
# Plot F1-Score
plt.bar(r4, f1_score, color='y', width=bar_width, edgecolor='grey', label='F1-Score')

# Labeling the plot
plt.xlabel('Models', fontweight='bold')
plt.ylabel('Scores', fontweight='bold')
plt.xticks([r + bar_width for r in range(len(models))], models)
plt.title('Comparison of VGG16 pre-trained and VGG16 models Performance Metrics')
plt.legend()
# Show the plot
plt.show()

# Load the pre-trained VGG16 model
model_path = 'VGG16_model.h5'
model = load_model(model_path,compile=False)

def load_and_preprocess_image(image_p, target_size=(224, 224)):
   # Read and convert the image to RGB
   image = cv2.imread(image_p)
   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
   # Resize the image to match model input size
   image = cv2.resize(image, target_size)
   # Convert image to array and normalize pixel values
   image = img_to_array(image) / 255.0
   # Expand dimensions to fit the model input shape (batch size of 1)
   image = np.expand_dims(image, axis=0)
   return image

def predict_image(model, image_p, class_labels):
    # Preprocess the image
    image = load_and_preprocess_image(image_p)
    # Predict the class probabilities
    predictions = model.predict(image)
    # Get the predicted class index
    predicted_class = np.argmax(predictions)
    # Map the predicted index to the class label
    predicted_label = class_labels[predicted_class]
    return predicted_label, predictions

# Define the class labels
class_labels = ["glioma","meningioma","notumor","pituitary"]

# Path to the image to be classified

image_p = 'dataset/Testing/notumor/Te-no_0019.jpg'

# Perform prediction
predicted_label, predictions = predict_image(model, image_p, class_labels)

# Read and display the image
image = cv2.imread(image_p)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
# Plot the image with the predicted label
plt.imshow(image)
plt.title(f'Predicted: {predicted_label}')
plt.axis('off')
plt.show()
# Plot the image with the predicted label
print(f'Prediction probabilities: {predictions}')

